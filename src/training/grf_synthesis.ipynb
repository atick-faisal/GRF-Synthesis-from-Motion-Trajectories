{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "grf_synthesis.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "b9e8b413bd195f698761fbb7f1cc8940f40efdff75a04973931ad61a6fc56074"
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "orig_nbformat": 4
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atick-faisal/GRF-Synthesis-from-Motion-Trajectories/blob/main/src/training/grf_synthesis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive._mount('/content/drive')"
      ],
      "metadata": {
        "id": "Ny5F1D53uh9Q"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6x_r50aIez0f"
      },
      "source": [
        "# !pip install --upgrade pandas==1.3.4"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j15cTL2I4oNu"
      },
      "source": [
        "# Download and prepare data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJcRThWM5LF5"
      },
      "source": [
        "# !gdown --id \"1kNGwWBQp6kmAioLP-_zWx7r42SzoEO3v\"\n",
        "# !unzip UNet.zip\n",
        "\n",
        "# !gdown --id \"1MafN0ICjXTriabpt1xHeJX2Ml_6gjfkt\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6XtngBS4oNt"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kpZ_68Q43j9"
      },
      "source": [
        "import h5py\n",
        "import scipy\n",
        "import random\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import scipy.io as sio\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import mean_squared_error, median_absolute_error, mean_absolute_error\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "from UNet_1DCNN import UNet\n",
        "from FPN_1DCNN import FPN\n",
        "from AlbuNet_1DCNN import AlbUNet\n",
        "\n",
        "%matplotlib inline\n",
        "sns.set(font_scale=1.5)\n",
        "sns.set_style(\"darkgrid\", {'font.family':'serif', 'font.serif':'Times New Roman'})\n",
        "\n",
        "models_dir = '/content/drive/MyDrive/Research/GRF Data Synthesis/Models/'\n",
        "figures_dir = '/content/drive/MyDrive/Research/GRF Data Synthesis/Figures/'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwCAfz544oNz"
      },
      "source": [
        "# Train test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwNGZwEg4oNz",
        "outputId": "b165d969-0f16-47eb-ea40-493aba740e41"
      },
      "source": [
        "data = joblib.load('/content/data2_f72_t3_n1_combined.joblib')\n",
        "X_Train = data['train_X']\n",
        "X_Test = data['test_X']\n",
        "Y_Train = data['train_y']\n",
        "Y_Test = data['test_y']\n",
        "\n",
        "print(X_Train.shape)\n",
        "print(X_Test.shape)\n",
        "print(Y_Train.shape)\n",
        "print(Y_Test.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3136, 1024, 36)\n",
            "(784, 1024, 36)\n",
            "(3136, 1024, 3)\n",
            "(784, 1024, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Axis Selection"
      ],
      "metadata": {
        "id": "k_ePJvmtegj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_Train = X_Train[:, :, [9, 11, 30, 31, 32, 33, 34, 35]]\n",
        "X_Test = X_Test[:, :, [9, 11, 30, 31, 32, 33, 34, 35]]\n",
        "Y_Train = Y_Train[:, :, 2]\n",
        "Y_Test = Y_Test[:, :, 2]\n",
        "\n",
        "print(X_Train.shape)\n",
        "print(X_Test.shape)\n",
        "print(Y_Train.shape)\n",
        "print(Y_Test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZKBWCVTeFFC",
        "outputId": "635f8cf8-8e7f-4a5c-b654-8331933d3a18"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3136, 1024, 8)\n",
            "(784, 1024, 8)\n",
            "(3136, 1024)\n",
            "(784, 1024)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FRAME_LEN = X_Train.shape[1]\n",
        "N_CHANNELS = X_Train.shape[2]"
      ],
      "metadata": {
        "id": "RIHHro2IeqP9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a1FRPZ74oN0"
      },
      "source": [
        "# Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30i1r3Ln4oN0"
      },
      "source": [
        "model_name = 'FPN' # UNet or UNetPP\n",
        "signal_length = FRAME_LEN # Length of each Segment\n",
        "model_depth = 5 # Number of Level in the CNN Model\n",
        "model_width = 64 # Width of the Initial Layer, subsequent layers start from here\n",
        "kernel_size = 3 # Size of the Kernels/Filter\n",
        "num_channel = N_CHANNELS # Number of Channels in the Model\n",
        "D_S = 1 # Turn on Deep Supervision\n",
        "A_E = 0 # Turn on AutoEncoder Mode for Feature Extraction\n",
        "A_G = 0 # Attention Guided\n",
        "problem_type = 'Regression'\n",
        "output_nums = 1 # Number of Class for Classification Problems, always '1' for Regression Problems\n",
        "'''Only required if the AutoEncoder Mode is turned on'''\n",
        "feature_number = 1024 # Number of Features to be Extracted\n",
        "'''Only required for MultiResUNet'''\n",
        "alpha = 1 # Model Width Expansion Parameter"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCdOOVOa4oN2"
      },
      "source": [
        "# Prepare for deep supervision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c61dm5v94oN3"
      },
      "source": [
        "def prepareTrainDict(y, model_depth, signal_length, model_name):\n",
        "  def approximate(inp, w_len, signal_length):\n",
        "    op = np.zeros((len(inp),signal_length//w_len))\n",
        "    for i in range(0,signal_length,w_len):\n",
        "      try:\n",
        "        op[:,i//w_len] = np.mean(inp[:,i:i+w_len],axis=1)\n",
        "      except Exception as e:\n",
        "        print(e)\n",
        "        print(i)\n",
        "  \t\n",
        "    return op\n",
        "\n",
        "  out = {}\n",
        "  Y_Train_dict = {}\n",
        "  out['out'] = np.array(y)\n",
        "  Y_Train_dict['out'] = out['out']\n",
        "  for i in range(1, (model_depth+1)):\n",
        "    name = f'level{i}'\n",
        "    if ((model_name == 'UNet') or (model_name == 'MultiResUNet') or (model_name == 'FPN')):\n",
        "      out[name] = np.expand_dims(approximate(np.squeeze(y), 2**i, signal_length),axis = 2)\n",
        "    elif ((model_name == 'UNetE') or (model_name == 'UNetP') or (model_name == 'UNetPP')):\n",
        "      out[name] = np.expand_dims(approximate(np.squeeze(y), 2**0, signal_length),axis = 2)\n",
        "    Y_Train_dict[f'level{i}'] = out[f'level{i}']\n",
        "  \n",
        "  return out, Y_Train_dict"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQqyFLjl4oN4"
      },
      "source": [
        "X_Train1 = X_Train\n",
        "X_Test1 = X_Test\n",
        "[Y_Train1, Y_Train_dict] = prepareTrainDict(Y_Train, model_depth, signal_length, model_name)\n",
        "[Y_Test1, Y_Test_dict] = prepareTrainDict(Y_Test, model_depth, signal_length, model_name)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_V8_Ht-4oN5",
        "outputId": "a7d851a1-c8a3-4497-9e89-cf982f16048d"
      },
      "source": [
        "loss_weights = np.zeros(model_depth)\n",
        "\n",
        "for i in range(0, model_depth):\n",
        "   loss_weights[i] = 1-(i*0.1)\n",
        "   \n",
        "loss_weights"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1. , 0.9, 0.8, 0.7, 0.6])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fK_K_tyy4oN5"
      },
      "source": [
        "# Build and compile model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-nTNzLM4oN5"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate = 0.001\n",
        ")\n",
        "\n",
        "if D_S == 0:\n",
        "    # Build model for EEG Motion Artifact Removal - Deep Unet Architecture\n",
        "    # AutoEncoder should be set at 'FALSE' for the Deep U-net model for Signal Reconstruction\n",
        "    # D_S = 0, A_E = 0\n",
        "    model = UNet(\n",
        "        signal_length,\n",
        "        model_depth,\n",
        "        num_channel, \n",
        "        model_width, \n",
        "        kernel_size, \n",
        "        problem_type=problem_type, \n",
        "        output_nums=output_nums, \n",
        "        ds=D_S,\n",
        "        ae=A_E, \n",
        "        ag=A_G,\n",
        "        alpha=alpha\n",
        "    ).UNet()\n",
        "\n",
        "    model.compile(\n",
        "        loss= 'mean_absolute_error', \n",
        "        optimizer= optimizer, \n",
        "        metrics= ['mean_squared_error','accuracy']\n",
        "    )\n",
        "    #\n",
        "elif D_S == 1:\n",
        "    # Build model for EEG Motion Artifact Removal - Deep Unet Architecture\n",
        "    # AutoEncoder should be set at 'FALSE' for the Deep U-net model for Signal Reconstruction\n",
        "    # D_S = 1, A_E = 0\n",
        "    model = FPN(\n",
        "        signal_length, model_depth, \n",
        "        num_channel, \n",
        "        model_width, \n",
        "        kernel_size, \n",
        "        problem_type=problem_type, \n",
        "        output_nums=output_nums, \n",
        "        ds=D_S,\n",
        "        ae=A_E,\n",
        "        ag=A_G, \n",
        "        #alpha=alpha\n",
        "    ).FPN()\n",
        "\n",
        "    model.compile(\n",
        "        loss= 'mean_absolute_error', \n",
        "        optimizer= optimizer, \n",
        "        metrics= ['mean_squared_error'], \n",
        "        loss_weights= loss_weights\n",
        "    )"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlLB1flN4oN6"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = model_name + '_' + str(signal_length) + '_' \\\n",
        "            + str(N_CHANNELS) + '_' + str(model_width) +'_' \\\n",
        "            + str(model_depth) + '_' + str(num_channel) + '_' \\\n",
        "            + str(D_S) + str(A_G)"
      ],
      "metadata": {
        "id": "IoH2_k-yPFkP"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7URRYEK4oN6",
        "outputId": "f5c499ef-4de9-450e-cda0-934be73b939d"
      },
      "source": [
        "if D_S == 0:\n",
        "    callbacks = [\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, mode='min'), \n",
        "        tf.keras.callbacks.ModelCheckpoint(\n",
        "            'trained_models/' + config +'.h5', \n",
        "                verbose=1, \n",
        "                monitor='val_loss', \n",
        "                save_best_only=True, \n",
        "                mode='min'\n",
        "        )\n",
        "    ]\n",
        "    history = model.fit(\n",
        "        X_Train, Y_Train, \n",
        "        epochs=300, \n",
        "        batch_size=64, \n",
        "        verbose=1, \n",
        "        validation_split=0.2, \n",
        "        shuffle=True, \n",
        "        callbacks=callbacks\n",
        "    )\n",
        "    \n",
        "elif D_S == 1:\n",
        "    callbacks = [\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_out_loss', patience=30, mode='min'), \n",
        "        tf.keras.callbacks.ModelCheckpoint(\n",
        "            'trained_models/' + config + '.h5', \n",
        "                verbose=1, \n",
        "                monitor='val_loss', \n",
        "                save_best_only=True, \n",
        "                mode='min'\n",
        "        )\n",
        "    ]\n",
        "    history = model.fit(\n",
        "        X_Train1, \n",
        "        Y_Train_dict, \n",
        "        epochs=300, \n",
        "        batch_size=64, \n",
        "        verbose=1, \n",
        "        validation_split=0.2, \n",
        "        shuffle=True, \n",
        "        callbacks=callbacks\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "40/40 [==============================] - ETA: 0s - loss: 2.0627 - out_loss: 0.4000 - level1_loss: 0.3068 - level2_loss: 0.3362 - level3_loss: 0.3872 - level4_loss: 0.4509 - level5_loss: 0.6973 - out_mean_squared_error: 1.3405 - level1_mean_squared_error: 0.4329 - level2_mean_squared_error: 0.7371 - level3_mean_squared_error: 1.3803 - level4_mean_squared_error: 1.8275 - level5_mean_squared_error: 3.8935\n",
            "Epoch 00001: val_loss improved from inf to 1.71698, saving model to trained_models/FPN_1024_8_64_5_8_10.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r40/40 [==============================] - 60s 887ms/step - loss: 2.0627 - out_loss: 0.4000 - level1_loss: 0.3068 - level2_loss: 0.3362 - level3_loss: 0.3872 - level4_loss: 0.4509 - level5_loss: 0.6973 - out_mean_squared_error: 1.3405 - level1_mean_squared_error: 0.4329 - level2_mean_squared_error: 0.7371 - level3_mean_squared_error: 1.3803 - level4_mean_squared_error: 1.8275 - level5_mean_squared_error: 3.8935 - val_loss: 1.7170 - val_out_loss: 0.3132 - val_level1_loss: 0.4853 - val_level2_loss: 0.3421 - val_level3_loss: 0.3050 - val_level4_loss: 0.4651 - val_level5_loss: 0.2357 - val_out_mean_squared_error: 0.1147 - val_level1_mean_squared_error: 0.2834 - val_level2_mean_squared_error: 0.1374 - val_level3_mean_squared_error: 0.1086 - val_level4_mean_squared_error: 0.2547 - val_level5_mean_squared_error: 0.0709\n",
            "Epoch 2/300\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.6099 - out_loss: 0.1218 - level1_loss: 0.1069 - level2_loss: 0.1105 - level3_loss: 0.1257 - level4_loss: 0.1820 - level5_loss: 0.1155 - out_mean_squared_error: 0.0318 - level1_mean_squared_error: 0.0233 - level2_mean_squared_error: 0.0247 - level3_mean_squared_error: 0.0292 - level4_mean_squared_error: 0.0722 - level5_mean_squared_error: 0.0287"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MflY4cE04oN7"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-4OM5vr4oN7"
      },
      "source": [
        "if D_S == 0:\n",
        "    GRF_pred = model.predict(X_Test, verbose=1)\n",
        "    print(GRF_pred.shape)\n",
        "elif D_S == 1:\n",
        "    GRF_pred = model.predict(X_Test1, verbose=1)\n",
        "    print(GRF_pred[0].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ground_truth_mean = np.mean(Y_Test, axis=0)\n",
        "ground_truth_std = np.std(Y_Test, axis=0)\n",
        "prediction = np.nan_to_num(GRF_pred[0][:, :, 0])\n",
        "prediction_mean = np.mean(prediction, axis=0)\n",
        "prediction_std = np.std(prediction, axis=0)"
      ],
      "metadata": {
        "id": "moGbBtKgG_MH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "R = np.corrcoef(ground_truth_mean, prediction_mean)[0, 1]"
      ],
      "metadata": {
        "id": "3Kl-nvENMN-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 7))\n",
        "x = np.linspace(0, 100, FRAME_LEN)\n",
        "plt.plot(x, ground_truth_mean, linewidth=3, label='Ground Truth')\n",
        "plt.fill_between(\n",
        "    x, ground_truth_mean + ground_truth_std,\n",
        "    ground_truth_mean - ground_truth_std, alpha=0.3,\n",
        "    label='Ground Truth +/- STD'\n",
        ")\n",
        "plt.plot(x, prediction_mean, linewidth=3, label='Prediction')\n",
        "plt.fill_between(\n",
        "    x, prediction_mean + prediction_std,\n",
        "    prediction_mean - prediction_std, alpha=0.3,\n",
        "    label='Prediction +/- STD'\n",
        ")\n",
        "plt.legend()\n",
        "plt.title(f'R = {round(R, 5)}')\n",
        "plt.xlabel('Stance Phase (%)')\n",
        "plt.ylabel('GRF N/Kg (Normalized)')\n",
        "plt.savefig(figures_dir + 'Results_Fz_' + config + '.pdf')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WcIRU_sFH-WA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save Model"
      ],
      "metadata": {
        "id": "cVQTMzbguxgA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from shutil import copy\n",
        "# copy('trained_models/' + config + '.h5', \n",
        "#         '/content/drive/MyDrive/Research/GRF Data Synthesis/Models/')\n",
        "joblib.dump(history, models_dir + \\\n",
        "            'History_' + config + '.joblib')"
      ],
      "metadata": {
        "id": "kOt1Gg7SutXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsW0dNyN4oN7"
      },
      "source": [
        "# Learning curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3Z2otb84oN7"
      },
      "source": [
        "def history_plot(history):\n",
        "    # list all dictionaries in history\n",
        "    print(history.history.keys())\n",
        "    # summarize history for error\n",
        "    plt.figure(figsize=(11,7))\n",
        "    plt.subplot(2,1,1)\n",
        "    plt.plot(history.history['out_mean_squared_error'])\n",
        "    plt.plot(history.history['val_out_mean_squared_error'])\n",
        "    plt.title('Model Error Performance')\n",
        "    plt.ylabel('Error')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Val'], loc='upper right')\n",
        "    #   plt.ylim([0, 3])\n",
        "    plt.show()\n",
        "    # summarize history for loss\n",
        "    plt.figure(figsize=(11,7))\n",
        "    plt.subplot(2,1,2)\n",
        "    plt.plot(history.history['out_loss'])\n",
        "    plt.plot(history.history['val_out_loss'])\n",
        "    plt.title('Model Loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Val'], loc='upper right')\n",
        "    #   plt.ylim([0, 3])\n",
        "    plt.savefig(figures_dir + 'LC_' + config + '.pdf')\n",
        "    plt.show()\n",
        "#\n",
        "history_plot(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYBK8ann4oN8"
      },
      "source": [
        "# Visualize outcomes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1f-mpSA34oN8"
      },
      "source": [
        "if D_S == 0:\n",
        "    random_idx = random.sample(range(0, Y_Test.shape[0]), 6)\n",
        "    plt.figure(figsize=(14, 9))\n",
        "    for i in range(6):\n",
        "        y_true = Y_Test[random_idx[i]]\n",
        "        y_pred = GRF_pred[random_idx[i]]\n",
        "        MAE = np.mean(np.abs(y_pred.ravel() - y_true.ravel()))\n",
        "        plt.subplot(2, 3, i + 1)\n",
        "        plt.plot(y_true, label='Ground Truth')\n",
        "        plt.plot(y_pred.ravel(), label='Prediction')\n",
        "        plt.title(f\"MAE [{random_idx[i]}] : {MAE}\")\n",
        "        plt.legend();\n",
        "    plt.show()\n",
        "    \n",
        "elif D_S == 1:\n",
        "    random_idx = random.sample(range(0, Y_Test.shape[0]), 6)\n",
        "    plt.figure(figsize=(14, 9))\n",
        "    for i in range(6):\n",
        "        y_true = Y_Test[random_idx[i]]\n",
        "        y_pred = GRF_pred[0][random_idx[i]]\n",
        "        MAE = np.mean(np.abs(y_pred.ravel() - y_true.ravel()))\n",
        "        plt.subplot(2, 3, i + 1)\n",
        "        plt.plot(y_true, label='Ground Truth', linewidth=3)\n",
        "        plt.plot(y_pred.ravel(), label='Prediction', linewidth=3)\n",
        "        plt.title(f\"MAE [{random_idx[i]}] : {round(MAE, 4)}\")\n",
        "        plt.legend()\n",
        "    plt.savefig(figures_dir + 'Examples_Fz_' + config + '.pdf')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3elq2yvb4oN8"
      },
      "source": [
        "# Construction Error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tivpIeIt738C"
      },
      "source": [
        "def Construction_Error(GRND, Pred):\n",
        "    construction_err = []\n",
        "    bad_indices = []\n",
        "    count = 0\n",
        "\n",
        "    for i in range(len(GRND)):\n",
        "        MAE = np.mean(np.abs(Pred[i].ravel() - GRND[i].ravel()))\n",
        "        if MAE < 1:\n",
        "            construction_err.append(MAE)\n",
        "        elif MAE >= 1:\n",
        "            count = count + 1\n",
        "            bad_indices.append(i)\n",
        "\n",
        "    print(f'Construction Error : {round(np.mean(construction_err), 3)} +/- {round(np.std(construction_err), 3)}')\n",
        "    print(f'Number of Bad Predictions = {count}')\n",
        "\n",
        "    bad_indices = set(bad_indices)\n",
        "    all_indices = set(np.arange(len(GRND)))\n",
        "    good_indices = np.array(list(all_indices - bad_indices))\n",
        "    GRND_NEW = GRND[good_indices]\n",
        "    PRED_NEW = Pred[good_indices]\n",
        "\n",
        "    return GRND_NEW, PRED_NEW"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5LZy8284oN9"
      },
      "source": [
        "[A,B] = Construction_Error(Y_Test, GRF_pred[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1P2HQPM4oN9"
      },
      "source": [
        "# Infinite loop to keep colab alive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HEA3DYo4oN9"
      },
      "source": [
        "while True:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}