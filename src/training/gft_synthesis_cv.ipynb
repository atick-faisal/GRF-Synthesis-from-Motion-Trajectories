{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gdown --id \"1kNGwWBQp6kmAioLP-_zWx7r42SzoEO3v\"\n",
    "# !unzip -u UNet.zip\n",
    "\n",
    "# !gdown --id \"1-0-jQ_yS6ojnosNeEYpy8f5tnpYLAd5b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import scipy\n",
    "import random\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error, median_absolute_error, mean_absolute_error\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "\n",
    "from UNet_1DCNN import UNet\n",
    "from FPN_1DCNN import FPN\n",
    "from AlbuNet_1DCNN import AlbUNet\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(font_scale=1.5)\n",
    "sns.set_style(\"darkgrid\", {'font.family': 'serif',\n",
    "              'font.serif': 'Times New Roman'})\n",
    "\n",
    "models_dir = '/content/drive/MyDrive/Research/GRF Data Synthesis/DB2/ModelsX/'\n",
    "figures_dir = '/content/drive/MyDrive/Research/GRF Data Synthesis/DB2/FiguresX/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareTrainDict(y, model_depth, signal_length, model_name):\n",
    "    def approximate(inp, w_len, signal_length):\n",
    "        op = np.zeros((len(inp), signal_length//w_len))\n",
    "        for i in range(0, signal_length, w_len):\n",
    "            try:\n",
    "                op[:, i//w_len] = np.mean(inp[:, i:i+w_len], axis=1)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(i)\n",
    "\n",
    "        return op\n",
    "\n",
    "    out = {}\n",
    "    Y_Train_dict = {}\n",
    "    out['out'] = np.array(y)\n",
    "    Y_Train_dict['out'] = out['out']\n",
    "    for i in range(1, (model_depth+1)):\n",
    "        name = f'level{i}'\n",
    "        if ((model_name == 'UNet') or (model_name == 'MultiResUNet') or (model_name == 'FPN')):\n",
    "            out[name] = np.expand_dims(approximate(\n",
    "                np.squeeze(y), 2**i, signal_length), axis=2)\n",
    "        elif ((model_name == 'UNetE') or (model_name == 'UNetP') or (model_name == 'UNetPP')):\n",
    "            out[name] = np.expand_dims(approximate(\n",
    "                np.squeeze(y), 2**0, signal_length), axis=2)\n",
    "        Y_Train_dict[f'level{i}'] = out[f'level{i}']\n",
    "\n",
    "    return out, Y_Train_dict\n",
    "\n",
    "\n",
    "def Construction_Error(GRND, Pred):\n",
    "    construction_err = []\n",
    "    rmse = []\n",
    "    corr_coef = []\n",
    "    corr_coef2 = []\n",
    "    bad_indices = []\n",
    "    count = 0\n",
    "\n",
    "    for i in range(len(GRND)):\n",
    "        MAE = np.mean(np.abs(Pred[i].ravel() - GRND[i].ravel()))\n",
    "        RMSE = mean_squared_error(np.nan_to_num(\n",
    "            Pred[i].ravel()), GRND[i].ravel(), squared=False)\n",
    "        R = np.corrcoef(np.nan_to_num(Pred[i].ravel()), GRND[i].ravel())[0, 1]\n",
    "        R2 = pearsonr(np.nan_to_num(Pred[i].ravel()), GRND[i].ravel())[0]\n",
    "        if MAE < 1:\n",
    "            construction_err.append(MAE)\n",
    "            rmse.append(RMSE)\n",
    "            corr_coef.append(R)\n",
    "            corr_coef2.append(R2)\n",
    "\n",
    "        elif MAE >= 1:\n",
    "            count = count + 1\n",
    "            bad_indices.append(i)\n",
    "\n",
    "    print(\n",
    "        f'Construction Error : {round(np.mean(construction_err), 3)} +/- {round(np.std(construction_err), 3)}')\n",
    "    print(f'RMSE : {round(np.mean(rmse), 3)} +/- {round(np.std(rmse), 3)}')\n",
    "    print(\n",
    "        f'R1 : {round(np.mean(corr_coef), 3)} +/- {round(np.std(corr_coef), 3)}')\n",
    "    print(\n",
    "        f'R2 : {round(np.mean(corr_coef2), 3)} +/- {round(np.std(corr_coef2), 3)}')\n",
    "    print(f'Number of Bad Predictions = {count}')\n",
    "\n",
    "    bad_indices = set(bad_indices)\n",
    "    all_indices = set(np.arange(len(GRND)))\n",
    "    good_indices = np.array(list(all_indices - bad_indices))\n",
    "    GRND_NEW = GRND[good_indices]\n",
    "    PRED_NEW = Pred[good_indices]\n",
    "\n",
    "    return GRND_NEW, PRED_NEW\n",
    "\n",
    "def history_plot(history):\n",
    "        # list all dictionaries in history\n",
    "        print(history.history.keys())\n",
    "        # summarize history for error\n",
    "        plt.figure(figsize=(11,14))\n",
    "        plt.subplot(2,1,1)\n",
    "        plt.plot(history.history['out_mean_squared_error'], linewidth=2)\n",
    "        plt.plot(history.history['val_out_mean_squared_error'], linewidth=2)\n",
    "        plt.title('Model Error Performance')\n",
    "        plt.ylabel('Error (MSE)')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(['Train', 'Val'], loc='upper right')\n",
    "        #   plt.ylim([0, 3])\n",
    "        # plt.savefig(figures_dir + 'EC_' + config + '.png')\n",
    "        # plt.show()\n",
    "        # summarize history for loss\n",
    "        # plt.figure(figsize=(11,7))\n",
    "        plt.subplot(2,1,2)\n",
    "        plt.plot(history.history['out_loss'], linewidth=2)\n",
    "        plt.plot(history.history['val_out_loss'], linewidth=2)\n",
    "        plt.title('Model Loss')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(['Train', 'Val'], loc='upper right')\n",
    "        #   plt.ylim([0, 3])\n",
    "        plt.savefig(figures_dir + 'LC_' + config + '.png')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'MultiResUNet'  # UNet or UNetPP\n",
    "# signal_length = FRAME_LEN  # Length of each Segment\n",
    "model_depth = 5  # Number of Level in the CNN Model\n",
    "model_width = 64  # Width of the Initial Layer, subsequent layers start from here\n",
    "kernel_size = 3  # Size of the Kernels/Filter\n",
    "# num_channel = N_CHANNELS  # Number of Channels in the Model\n",
    "D_S = 1  # Turn on Deep Supervision\n",
    "A_E = 0  # Turn on AutoEncoder Mode for Feature Extraction\n",
    "A_G = 1  # Attention Guided\n",
    "problem_type = 'Regression'\n",
    "# Number of Class for Classification Problems, always '1' for Regression Problems\n",
    "output_nums = 1\n",
    "'''Only required if the AutoEncoder Mode is turned on'''\n",
    "feature_number = 1024  # Number of Features to be Extracted\n",
    "'''Only required for MultiResUNet'''\n",
    "alpha = 1  # Model Width Expansion Parameter\n",
    "\n",
    "EPOCHS = 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = None\n",
    "y = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "    X_Train, X_Test = X[train_idx], X[test_idx]\n",
    "    Y_Train, Y_Test = y[train_idx], y[test_idx]\n",
    "\n",
    "    print(X_Train.shape)\n",
    "    print(X_Test.shape)\n",
    "    print(Y_Train.shape)\n",
    "    print(Y_Test.shape)\n",
    "\n",
    "    FRAME_LEN = X_Train.shape[1]\n",
    "    N_CHANNELS = X_Train.shape[2]\n",
    "    signal_length = FRAME_LEN\n",
    "    num_channel = N_CHANNELS\n",
    "\n",
    "    #########################################################################################\n",
    "    X_Train1 = X_Train\n",
    "    X_Test1 = X_Test\n",
    "    [Y_Train1, Y_Train_dict] = prepareTrainDict(\n",
    "        Y_Train, model_depth, signal_length, model_name)\n",
    "    [Y_Test1, Y_Test_dict] = prepareTrainDict(\n",
    "        Y_Test, model_depth, signal_length, model_name)\n",
    "    #########################################################################################\n",
    "    loss_weights = np.zeros(model_depth)\n",
    "    for i in range(0, model_depth):\n",
    "        loss_weights[i] = 1-(i*0.1)\n",
    "    loss_weights\n",
    "    #########################################################################################\n",
    "    optimizer = tf.keras.optimizers.Adam(\n",
    "        learning_rate=0.001\n",
    "    )\n",
    "\n",
    "    if D_S == 0:\n",
    "        # Build model for EEG Motion Artifact Removal - Deep Unet Architecture\n",
    "        # AutoEncoder should be set at 'FALSE' for the Deep U-net model for Signal Reconstruction\n",
    "        # D_S = 0, A_E = 0\n",
    "        model = UNet(\n",
    "            signal_length,\n",
    "            model_depth,\n",
    "            num_channel,\n",
    "            model_width,\n",
    "            kernel_size,\n",
    "            problem_type=problem_type,\n",
    "            output_nums=output_nums,\n",
    "            ds=D_S,\n",
    "            ae=A_E,\n",
    "            ag=A_G,\n",
    "            alpha=alpha\n",
    "        ).UNet()\n",
    "\n",
    "        model.compile(\n",
    "            loss='mean_absolute_error',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['mean_squared_error', 'accuracy']\n",
    "        )\n",
    "        #\n",
    "    elif D_S == 1:\n",
    "        # Build model for EEG Motion Artifact Removal - Deep Unet Architecture\n",
    "        # AutoEncoder should be set at 'FALSE' for the Deep U-net model for Signal Reconstruction\n",
    "        # D_S = 1, A_E = 0\n",
    "        model = UNet(\n",
    "            signal_length, model_depth,\n",
    "            num_channel,\n",
    "            model_width,\n",
    "            kernel_size,\n",
    "            problem_type=problem_type,\n",
    "            output_nums=output_nums,\n",
    "            ds=D_S,\n",
    "            ae=A_E,\n",
    "            ag=A_G,\n",
    "            alpha=alpha\n",
    "        ).MultiResUNet()\n",
    "\n",
    "        model.compile(\n",
    "            loss='mean_absolute_error',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['mean_squared_error'],\n",
    "            loss_weights=loss_weights\n",
    "        )\n",
    "    #################################################################################\n",
    "    config = model_name + '_moment_' + str(signal_length) + '_' \\\n",
    "        + str(N_CHANNELS) + '_' + str(model_width) + '_' \\\n",
    "        + str(model_depth) + '_' + str(num_channel) + '_all_vel_' \\\n",
    "        + str(D_S) + str(A_G) + '_axis_corrected'\n",
    "    #################################################################################\n",
    "    if D_S == 0:\n",
    "        callbacks = [\n",
    "            tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, mode='min'), \n",
    "            tf.keras.callbacks.ModelCheckpoint(\n",
    "                'trained_models/' + config +'.h5', \n",
    "                    verbose=1, \n",
    "                    monitor='val_loss', \n",
    "                    save_best_only=True, \n",
    "                    mode='min'\n",
    "            )\n",
    "        ]\n",
    "        history = model.fit(\n",
    "            X_Train, Y_Train, \n",
    "            epochs=EPOCHS, \n",
    "            batch_size=64, \n",
    "            verbose=1, \n",
    "            validation_split=0.2, \n",
    "            shuffle=True, \n",
    "            callbacks=callbacks\n",
    "        )\n",
    "        \n",
    "    elif D_S == 1:\n",
    "        callbacks = [\n",
    "            tf.keras.callbacks.EarlyStopping(monitor='val_out_loss', patience=30, mode='min'), \n",
    "            tf.keras.callbacks.ModelCheckpoint(\n",
    "                'trained_models/' + config + '.h5', \n",
    "                    verbose=1, \n",
    "                    monitor='val_loss', \n",
    "                    save_best_only=True, \n",
    "                    mode='min'\n",
    "            )\n",
    "        ]\n",
    "        history = model.fit(\n",
    "            X_Train1, \n",
    "            Y_Train_dict, \n",
    "            epochs=EPOCHS, \n",
    "            batch_size=64, \n",
    "            verbose=1, \n",
    "            validation_split=0.2, \n",
    "            shuffle=True, \n",
    "            callbacks=callbacks\n",
    "        )\n",
    "    #################################################################################\n",
    "    if D_S == 0:\n",
    "        GRF_pred = model.predict(X_Test, verbose=1)\n",
    "        print(GRF_pred.shape)\n",
    "    elif D_S == 1:\n",
    "        GRF_pred = model.predict(X_Test1, verbose=1)\n",
    "        print(GRF_pred[0].shape)\n",
    "    #################################################################################\n",
    "    ground_truth_mean = np.mean(Y_Test, axis=0)\n",
    "    ground_truth_std = np.std(Y_Test, axis=0)\n",
    "    prediction = np.nan_to_num(GRF_pred[0][:, :, 0])\n",
    "    prediction_mean = np.mean(prediction, axis=0)\n",
    "    prediction_std = np.std(prediction, axis=0)\n",
    "    #################################################################################\n",
    "    R = np.corrcoef(ground_truth_mean, prediction_mean)[0, 1]\n",
    "    R2 = pearsonr(ground_truth_mean, prediction_mean)[0]\n",
    "    #################################################################################\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    x = np.linspace(0, 100, FRAME_LEN)\n",
    "    plt.plot(x, ground_truth_mean, linewidth=3, label='Ground Truth')\n",
    "    plt.fill_between(\n",
    "        x, ground_truth_mean + ground_truth_std,\n",
    "        ground_truth_mean - ground_truth_std, alpha=0.3,\n",
    "        label='Ground Truth +/- STD'\n",
    "    )\n",
    "    plt.plot(x, prediction_mean, linewidth=3, label='Prediction')\n",
    "    plt.fill_between(\n",
    "        x, prediction_mean + prediction_std,\n",
    "        prediction_mean - prediction_std, alpha=0.3,\n",
    "        label='Prediction +/- STD'\n",
    "    )\n",
    "    plt.legend()\n",
    "    plt.title(f'R1 = {round(R, 5)}, R2 = {round(R2, 5)}')\n",
    "    plt.xlabel('Stance Phase (%)')\n",
    "    plt.ylabel('Moment Nm (Normalized)')\n",
    "    plt.savefig(figures_dir + 'Results_' + config + '.png')\n",
    "    plt.show()\n",
    "    ################################################################################\n",
    "    from shutil import copy\n",
    "    copy('trained_models/' + config + '.h5', models_dir)\n",
    "    joblib.dump(history, models_dir + \\\n",
    "                'History_' + config + '.joblib')\n",
    "    ################################################################################\n",
    "    history_plot(history)\n",
    "    if D_S == 0:\n",
    "        random_idx = random.sample(range(0, Y_Test.shape[0]), 6)\n",
    "        plt.figure(figsize=(14, 9))\n",
    "        for i in range(6):\n",
    "            y_true = Y_Test[random_idx[i]]\n",
    "            y_pred = GRF_pred[random_idx[i]]\n",
    "            MAE = np.mean(np.abs(y_pred.ravel() - y_true.ravel()))\n",
    "            plt.subplot(2, 3, i + 1)\n",
    "            plt.plot(y_true, label='Ground Truth')\n",
    "            plt.plot(y_pred.ravel(), label='Prediction')\n",
    "            plt.title(f\"MAE [{random_idx[i]}] : {MAE}\")\n",
    "            plt.legend();\n",
    "        plt.show()\n",
    "        \n",
    "    elif D_S == 1:\n",
    "        random_idx = random.sample(range(0, Y_Test.shape[0]), 6)\n",
    "        plt.figure(figsize=(14, 9))\n",
    "        for i in range(6):\n",
    "            y_true = Y_Test[random_idx[i]]\n",
    "            y_pred = GRF_pred[0][random_idx[i]]\n",
    "            MAE = np.mean(np.abs(y_pred.ravel() - y_true.ravel()))\n",
    "            plt.subplot(2, 3, i + 1)\n",
    "            plt.plot(y_true, label='Ground Truth', linewidth=3)\n",
    "            plt.plot(y_pred.ravel(), label='Prediction', linewidth=3)\n",
    "            plt.title(f\"MAE [{random_idx[i]}] : {round(MAE, 4)}\")\n",
    "            plt.legend()\n",
    "        plt.savefig(figures_dir + 'Examples_Fy_' + config + '.png')\n",
    "        plt.show()\n",
    "\n",
    "    #############################################################################\n",
    "    [A,B] = Construction_Error(Y_Test, GRF_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
