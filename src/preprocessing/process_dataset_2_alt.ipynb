{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LhiDHswgZBby"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gc\n",
        "import h5py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from ezc3d import c3d\n",
        "from scipy.signal import resample\n",
        "from scipy.io import loadmat, savemat\n",
        "from scipy import sparse\n",
        "from scipy.sparse.linalg import spsolve\n",
        "from joblib import load, dump\n",
        "from tqdm import tqdm\n",
        "from scipy.signal import butter, lfilter, medfilt\n",
        "\n",
        "# %matplotlib qt\n",
        "sns.set(font_scale=1.5)\n",
        "sns.set_style(\"white\", {'font.family':'serif', 'font.serif':'Times New Roman'})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlkxCf8PZjwJ",
        "outputId": "af02dbf7-3cdf-481f-baa7-ea5c484f23a4"
      },
      "outputs": [],
      "source": [
        "PATH_DATASETS = '../../Dataset/'\n",
        "PATH_DATASET_2 = 'gait-dbase-2/'\n",
        "\n",
        "N_SAMPLES = 1024\n",
        "FORCE_THRESHOLD = 20\n",
        "TOE_HEIGTH_THRESHOLD = 40"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Filter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LowPassFilter(object): \n",
        "    @staticmethod\n",
        "    def butter_lowpass(cutoff, fs, order):\n",
        "        nyq = 0.5 * fs\n",
        "        normal_cutoff = cutoff / nyq\n",
        "        b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "        return b, a\n",
        "\n",
        "    def apply(data, cutoff=6, fs=2000, order=2, axis=-1):\n",
        "        b, a = LowPassFilter.butter_lowpass(cutoff, fs, order=order)\n",
        "        y = lfilter(b, a, data, axis=axis)\n",
        "        y = y - np.median(y)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Function Defs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def standardize(x):\n",
        "    # return (x - np.mean(x, axis=0)) / np.std(x, axis=0)\n",
        "    return (x - np.min(x, axis=0)) / (np.max(x, axis=0) - np.min(x, axis=0))\n",
        "\n",
        "def require_positive(x):\n",
        "    if x < 0:\n",
        "        return 0\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "def clip_overflow(x, max=N_SAMPLES):\n",
        "    if x >= max:\n",
        "        return N_SAMPLES - 1\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "def clip_noise(x, min=FORCE_THRESHOLD):\n",
        "    mask = x > min\n",
        "    new_x = np.zeros(x.shape)\n",
        "    new_x[mask] = x[mask]\n",
        "    return new_x\n",
        "\n",
        "def get_first_grf(x, swing_period):\n",
        "    half_way = x.shape[0] / 2\n",
        "    temp = np.zeros(x.shape)\n",
        "    temp[:half_way] = x[:half_way]\n",
        "    stance_mask = temp < FORCE_THRESHOLD\n",
        "    stance_start = np.min(stance_mask == True)\n",
        "    stance_end = np.max(stance_mask == True)\n",
        "    roi_start = stance_start\n",
        "    roi_end = stance_end + swing_period\n",
        "    return temp[roi_start : roi_end]\n",
        "\n",
        "def get_processed_grf(grf, clip=False):\n",
        "    processed_grf = LowPassFilter.apply(grf, fs=2000, cutoff=15)\n",
        "    if clip:\n",
        "        processed_grf[processed_grf < FORCE_THRESHOLD] = 0\n",
        "    return resample(processed_grf, N_SAMPLES * 4, axis=0).T\n",
        "\n",
        "def get_processed_moment(moment):\n",
        "    processed_moment = LowPassFilter.apply(moment, fs=2000, cutoff=15)\n",
        "    return resample(processed_moment, N_SAMPLES * 4, axis=0).T\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use trajectories-z 6-9 for y-axis\n",
        "\n",
        "def get_trajectories(content, foot='right'):\n",
        "    trajectory_x, trajectory_y = (None, None)\n",
        "    if foot == 'right':\n",
        "        # trajectory_x = content['data']['points'][0, 18:23, :]\n",
        "        # trajectory_y = content['data']['points'][1, 18:23, :]\n",
        "        trajectory_z = content['data']['points'][2, 18:23, :]\n",
        "\n",
        "    elif foot == 'left':\n",
        "        # trajectory_x = content['data']['points'][0, 6:11, :]\n",
        "        # trajectory_y = content['data']['points'][1, 6:11, :]\n",
        "        trajectory_z = content['data']['points'][2, 6:11, :]\n",
        "\n",
        "    else:\n",
        "        raise ValueError('Third foot is not allowed')\n",
        "\n",
        "    # trajectory_x = LowPassFilter.apply(trajectory_x, fs=200, cutoff=6, order=4)\n",
        "    # trajectory_y = LowPassFilter.apply(trajectory_y, fs=200, cutoff=6, order=4)\n",
        "    trajectory_z = LowPassFilter.apply(trajectory_z, fs=200, cutoff=6, order=4)\n",
        "\n",
        "    # trajectory_x = resample(trajectory_x, N_SAMPLES * 4, axis=1).T\n",
        "    # trajectory_y = resample(trajectory_y, N_SAMPLES * 4, axis=1).T\n",
        "    trajectory_z = resample(trajectory_z, N_SAMPLES * 4, axis=1).T\n",
        "\n",
        "    return trajectory_x, trajectory_y, trajectory_z\n",
        "\n",
        "def get_force(content):\n",
        "    force_x = []\n",
        "    force_y = []\n",
        "    force_z = []\n",
        "    for i in range(1, 5):\n",
        "        force_x.append(\n",
        "            get_processed_grf(\n",
        "                content['data']['platform'][i]['force'][0, :]\n",
        "            )\n",
        "        )\n",
        "        force_y.append(\n",
        "            get_processed_grf(\n",
        "                content['data']['platform'][i]['force'][1, :]\n",
        "            )\n",
        "        )\n",
        "        force_z.append(\n",
        "            get_processed_grf(\n",
        "                content['data']['platform'][i]['force'][2, :], True\n",
        "            )\n",
        "        )\n",
        "\n",
        "    return force_x, force_y, force_z\n",
        "\n",
        "def get_moment(content):\n",
        "    moment_x = []\n",
        "    moment_y = []\n",
        "    moment_z = []\n",
        "    for i in range(1, 5):\n",
        "        moment_x.append(\n",
        "            get_processed_moment(\n",
        "                content['data']['platform'][i]['moment'][0, :]\n",
        "            )\n",
        "        )\n",
        "        moment_y.append(\n",
        "            get_processed_moment(\n",
        "                content['data']['platform'][i]['moment'][1, :]\n",
        "            )\n",
        "        )\n",
        "        moment_z.append(\n",
        "            get_processed_moment(\n",
        "                content['data']['platform'][i]['moment'][2, :]\n",
        "            )\n",
        "        )\n",
        "\n",
        "    return moment_x, moment_y, moment_z\n",
        "\n",
        "def get_swing_period(force_plate_data_z):\n",
        "    grf_combined_z_r = force_plate_data_z[0] + force_plate_data_z[2]\n",
        "    grf_combined_z_l = force_plate_data_z[1] + force_plate_data_z[3]\n",
        "\n",
        "    grf_mask_r = (grf_combined_z_r >= FORCE_THRESHOLD)\n",
        "    grf_mask_l = (grf_combined_z_l >= FORCE_THRESHOLD)\n",
        "\n",
        "    grf_start_r = np.min(np.argwhere(grf_mask_r == True))\n",
        "    grf_end_r = np.max(np.argwhere(grf_mask_r == True))\n",
        "    grf_start_l = np.min(np.argwhere(grf_mask_l == True))\n",
        "    grf_end_l = np.max(np.argwhere(grf_mask_l == True))\n",
        "\n",
        "    swing_period_r = np.sum(grf_combined_z_r[grf_start_r:grf_end_r] <= FORCE_THRESHOLD)\n",
        "    swing_period_l = np.sum(grf_combined_z_l[grf_start_l:grf_end_l] <= FORCE_THRESHOLD)\n",
        "\n",
        "    return swing_period_r, swing_period_l\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test Bench"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "path = '/home/ai/Python/GRF-Synthesis-from-Motion-Trajectories/Dataset/gait-dbase-2/Participant3/Raw_Data/V35/T1.c3d'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "content = c3d(path, extract_forceplat_data=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Extract Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FJ5MckVigEFX"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▋         | 1/16 [01:03<15:52, 63.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ERROR [Participant11/V1/T8.c3d]: zero-size array to reduction operation minimum which has no identity\n",
            "ERROR [Participant11/V15/T6.c3d]: zero-size array to reduction operation minimum which has no identity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 31%|███▏      | 5/16 [05:20<11:26, 62.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ERROR [Participant4/V1/T2.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant4/V1/T8.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant4/V1/T1.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant4/V1/T7.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant4/V1/T9.c3d]: zero-size array to reduction operation minimum which has no identity\n",
            "ERROR [Participant4/V1/T4.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant4/V1/T5.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant4/V1/T3.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant4/V1/T6.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 38%|███▊      | 6/16 [06:13<09:55, 59.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ERROR [Participant14/V3/T2.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V3/T8.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V3/T1.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V3/T7.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V3/T9.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V3/T4.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V3/T5.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V3/T10.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V3/T3.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V3/T6.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V1/T2.c3d]: zero-size array to reduction operation minimum which has no identity\n",
            "ERROR [Participant14/V1/T8.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V1/T1.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V1/T7.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V1/T9.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V1/T4.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V1/T5.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V1/T10.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V1/T3.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V1/T6.c3d]: zero-size array to reduction operation minimum which has no identity\n",
            "ERROR [Participant14/V15/T2.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V15/T8.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V15/T1.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V15/T7.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V15/T9.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V15/T4.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V15/T5.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V15/T10.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V15/T3.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V15/T6.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V2/T2.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V2/T8.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V2/T1.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V2/T7.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V2/T9.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V2/T4.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V2/T5.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V2/T10.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V2/T3.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V2/T6.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V35/T2.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V35/T8.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V35/T1.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V35/T7.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V35/T9.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V35/T4.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V35/T5.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V35/T10.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V35/T3.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V35/T6.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V25/T2.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V25/T8.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V25/T1.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V25/T7.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V25/T9.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V25/T4.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V25/T5.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V25/T10.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V25/T3.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V25/T6.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V4/T2.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V4/T8.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V4/T1.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V4/T7.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V4/T9.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V4/T4.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V4/T5.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n",
            "ERROR [Participant14/V4/T3.c3d]: zero-size array to reduction operation minimum which has no identity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 44%|████▍     | 7/16 [07:16<09:04, 60.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ERROR [Participant14/V4/T6.c3d]: Shape of passed values is (1024, 4), indices imply (1024, 5)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [17:14<00:00, 64.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of good samples:  980\n",
            "Number of bad samples:  80\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "path = os.path.join(PATH_DATASETS, PATH_DATASET_2)\n",
        "subjects = os.listdir(path)\n",
        "\n",
        "# subjects = subjects[:8]\n",
        "\n",
        "features = pd.DataFrame()\n",
        "target = pd.DataFrame()\n",
        "\n",
        "records = []\n",
        "n_samples = 0\n",
        "n_bad_samples = 0\n",
        "\n",
        "# ax1 = plt.axes(projection='3d')\n",
        "\n",
        "for subject in tqdm(subjects):\n",
        "    velocities_path = os.path.join(path, subject, \"Raw_Data\")\n",
        "    velocities = os.listdir(velocities_path)\n",
        "\n",
        "    for velocity in velocities:\n",
        "\n",
        "        # if 'V1' in velocity or 'V15' in velocity or 'V2' in velocity or 'V25' in velocity:\n",
        "        #     continue\n",
        "\n",
        "        files_path = os.path.join(velocities_path, velocity)\n",
        "        files = os.listdir(files_path)\n",
        "\n",
        "        for filename in files:\n",
        "            try:\n",
        "                content = c3d(\n",
        "                    os.path.join(files_path, filename), extract_forceplat_data=True\n",
        "                )\n",
        "\n",
        "                trajectory_x_r, trajectory_y_r, trajectory_z_r = get_trajectories(\n",
        "                    content, \"right\"\n",
        "                )\n",
        "                trajectory_x_l, trajectory_y_l, trajectory_z_l = get_trajectories(\n",
        "                    content, \"left\"\n",
        "                )\n",
        "\n",
        "                # ax1.plot3D(trajectory_y_r[:, 3], trajectory_x_r[:, 3], trajectory_z_r[:, 3])\n",
        "\n",
        "                force_x, force_y, force_z = get_force(content)\n",
        "                moment_x, moment_y, moment_z = get_moment(content)\n",
        "                swing_period_r, swing_period_l = get_swing_period(force_z)\n",
        "\n",
        "                del content\n",
        "                gc.collect()\n",
        "\n",
        "                mask_force_z_r_1 = force_z[0] > FORCE_THRESHOLD\n",
        "                mask_force_z_r_2 = force_z[2] > FORCE_THRESHOLD\n",
        "                mask_force_z_l_1 = force_z[1] > FORCE_THRESHOLD\n",
        "                mask_force_z_l_2 = force_z[3] > FORCE_THRESHOLD\n",
        "\n",
        "                # ----------------------- RIGHT ------------------------\n",
        "\n",
        "                start = np.min(np.argwhere(mask_force_z_r_1 == True))\n",
        "                end = np.max(np.argwhere(mask_force_z_r_1 == True))  # + swing_period_r\n",
        "\n",
        "                force_x_r_1 = -force_x[0][start:end]\n",
        "                force_y_r_1 = force_y[0][start:end]\n",
        "                force_z_r_1 = force_z[0][start:end]\n",
        "\n",
        "                moment_x_r_1 = moment_x[0][start:end]\n",
        "                moment_y_r_1 = moment_y[0][start:end]\n",
        "                moment_z_r_1 = moment_z[0][start:end]\n",
        "\n",
        "                # trajectory_x_r_1 = trajectory_x_l[start:end]\n",
        "                # trajectory_y_r_1 = trajectory_y_r[start:end]\n",
        "                trajectory_z_r_1 = trajectory_z_r[start:end]\n",
        "\n",
        "                start = np.min(np.argwhere(mask_force_z_r_2 == True))\n",
        "                end = np.max(np.argwhere(mask_force_z_r_2 == True))  # + swing_period_r\n",
        "\n",
        "                force_x_r_2 = -force_x[2][start:end]\n",
        "                force_y_r_2 = force_y[2][start:end]\n",
        "                force_z_r_2 = force_z[2][start:end]\n",
        "\n",
        "                moment_x_r_2 = moment_x[2][start:end]\n",
        "                moment_y_r_2 = -moment_y[2][start:end]\n",
        "                moment_z_r_2 = -moment_z[2][start:end]\n",
        "\n",
        "                # trajectory_x_r_2 = trajectory_x_l[start:end]\n",
        "                # trajectory_y_r_2 = trajectory_y_r[start:end]\n",
        "                trajectory_z_r_2 = trajectory_z_r[start:end]\n",
        "\n",
        "                # ----------------------- LEFT ------------------------\n",
        "\n",
        "                start = np.min(np.argwhere(mask_force_z_l_1 == True))\n",
        "                end = np.max(np.argwhere(mask_force_z_l_1 == True))  # + swing_period_l\n",
        "\n",
        "                force_x_l_1 = force_x[1][start:end]\n",
        "                force_y_l_1 = force_y[1][start:end]\n",
        "                force_z_l_1 = force_z[1][start:end]\n",
        "\n",
        "                moment_x_l_1 = moment_x[1][start:end]\n",
        "                moment_y_l_1 = moment_y[1][start:end]\n",
        "                moment_z_l_1 = moment_z[1][start:end]\n",
        "\n",
        "                # trajectory_x_l_1 = trajectory_x_r[start:end]\n",
        "                # trajectory_y_l_1 = trajectory_y_l[start:end]\n",
        "                trajectory_z_l_1 = trajectory_z_l[start:end]\n",
        "\n",
        "                start = np.min(np.argwhere(mask_force_z_l_2 == True))\n",
        "                end = np.max(np.argwhere(mask_force_z_l_2 == True))  # + swing_period_l\n",
        "\n",
        "                force_x_l_2 = force_x[3][start:end]\n",
        "                force_y_l_2 = force_y[3][start:end]\n",
        "                force_z_l_2 = force_z[3][start:end]\n",
        "\n",
        "                moment_x_l_2 = moment_x[3][start:end]\n",
        "                moment_y_l_2 = -moment_y[3][start:end]\n",
        "                moment_z_l_2 = -moment_z[3][start:end]\n",
        "\n",
        "                # trajectory_x_l_2 = trajectory_x_r[start:end]\n",
        "                # trajectory_y_l_2 = trajectory_y_l[start:end]\n",
        "                trajectory_z_l_2 = trajectory_z_l[start:end]\n",
        "\n",
        "                # ... Remove all zero GRF samples\n",
        "                # if np.mean(force_z_2) <= FORCE_THRESHOLD or np.mean(force_z_3) <= FORCE_THRESHOLD \\\n",
        "                #     or np.mean(force_z_4) <= FORCE_THRESHOLD or np.mean(force_z_5) <= FORCE_THRESHOLD:\n",
        "                #     n_bad_samples = n_bad_samples + 1\n",
        "                #     continue\n",
        "\n",
        "                # ... Resample\n",
        "                force_x_r_1 = resample(force_x_r_1, N_SAMPLES, axis=0)\n",
        "                force_x_l_1 = resample(force_x_l_1, N_SAMPLES, axis=0)\n",
        "                force_x_r_2 = resample(force_x_r_2, N_SAMPLES, axis=0)\n",
        "                force_x_l_2 = resample(force_x_l_2, N_SAMPLES, axis=0)\n",
        "\n",
        "                force_y_r_1 = resample(force_y_r_1, N_SAMPLES, axis=0)\n",
        "                force_y_l_1 = resample(force_y_l_1, N_SAMPLES, axis=0)\n",
        "                force_y_r_2 = resample(force_y_r_2, N_SAMPLES, axis=0)\n",
        "                force_y_l_2 = resample(force_y_l_2, N_SAMPLES, axis=0)\n",
        "\n",
        "                force_z_r_1 = resample(force_z_r_1, N_SAMPLES, axis=0)\n",
        "                force_z_l_1 = resample(force_z_l_1, N_SAMPLES, axis=0)\n",
        "                force_z_r_2 = resample(force_z_r_2, N_SAMPLES, axis=0)\n",
        "                force_z_l_2 = resample(force_z_l_2, N_SAMPLES, axis=0)\n",
        "\n",
        "                moment_x_r_1 = resample(moment_x_r_1, N_SAMPLES, axis=0)\n",
        "                moment_x_l_1 = resample(moment_x_l_1, N_SAMPLES, axis=0)\n",
        "                moment_x_r_2 = resample(moment_x_r_2, N_SAMPLES, axis=0)\n",
        "                moment_x_l_2 = resample(moment_x_l_2, N_SAMPLES, axis=0)\n",
        "\n",
        "                moment_y_r_1 = resample(moment_y_r_1, N_SAMPLES, axis=0)\n",
        "                moment_y_l_1 = resample(moment_y_l_1, N_SAMPLES, axis=0)\n",
        "                moment_y_r_2 = resample(moment_y_r_2, N_SAMPLES, axis=0)\n",
        "                moment_y_l_2 = resample(moment_y_l_2, N_SAMPLES, axis=0)\n",
        "\n",
        "                moment_z_r_1 = resample(moment_z_r_1, N_SAMPLES, axis=0)\n",
        "                moment_z_l_1 = resample(moment_z_l_1, N_SAMPLES, axis=0)\n",
        "                moment_z_r_2 = resample(moment_z_r_2, N_SAMPLES, axis=0)\n",
        "                moment_z_l_2 = resample(moment_z_l_2, N_SAMPLES, axis=0)\n",
        "\n",
        "                # trajectory_x_r_1 = resample(trajectory_x_r_1, N_SAMPLES, axis=0)\n",
        "                # trajectory_x_r_2 = resample(trajectory_x_r_2, N_SAMPLES, axis=0)\n",
        "                # trajectory_x_l_1 = resample(trajectory_x_l_1, N_SAMPLES, axis=0)\n",
        "                # trajectory_x_l_2 = resample(trajectory_x_l_2, N_SAMPLES, axis=0)\n",
        "\n",
        "                # trajectory_y_r_1 = resample(trajectory_y_r_1, N_SAMPLES, axis=0)\n",
        "                # trajectory_y_r_2 = resample(trajectory_y_r_2, N_SAMPLES, axis=0)\n",
        "                # trajectory_y_l_1 = resample(trajectory_y_l_1, N_SAMPLES, axis=0)\n",
        "                # trajectory_y_l_2 = resample(trajectory_y_l_2, N_SAMPLES, axis=0)\n",
        "\n",
        "                trajectory_z_r_1 = resample(trajectory_z_r_1, N_SAMPLES, axis=0)\n",
        "                trajectory_z_r_2 = resample(trajectory_z_r_2, N_SAMPLES, axis=0)\n",
        "                trajectory_z_l_1 = resample(trajectory_z_l_1, N_SAMPLES, axis=0)\n",
        "                trajectory_z_l_2 = resample(trajectory_z_l_2, N_SAMPLES, axis=0)\n",
        "\n",
        "                # ... Standardize\n",
        "                force_x_r_1 = standardize(force_x_r_1)\n",
        "                force_x_l_1 = standardize(force_x_l_1)\n",
        "                force_x_r_2 = standardize(force_x_r_2)\n",
        "                force_x_l_2 = standardize(force_x_l_2)\n",
        "\n",
        "                force_y_r_1 = standardize(force_y_r_1)\n",
        "                force_y_l_1 = standardize(force_y_l_1)\n",
        "                force_y_r_2 = standardize(force_y_r_2)\n",
        "                force_y_l_2 = standardize(force_y_l_2)\n",
        "\n",
        "                force_z_r_1 = standardize(force_z_r_1)\n",
        "                force_z_l_1 = standardize(force_z_l_1)\n",
        "                force_z_r_2 = standardize(force_z_r_2)\n",
        "                force_z_l_2 = standardize(force_z_l_2)\n",
        "\n",
        "                moment_x_r_1 = standardize(moment_x_r_1)\n",
        "                moment_x_l_1 = standardize(moment_x_l_1)\n",
        "                moment_x_r_2 = standardize(moment_x_r_2)\n",
        "                moment_x_l_2 = standardize(moment_x_l_2)\n",
        "\n",
        "                moment_y_r_1 = standardize(moment_y_r_1)\n",
        "                moment_y_l_1 = standardize(moment_y_l_1)\n",
        "                moment_y_r_2 = standardize(moment_y_r_2)\n",
        "                moment_y_l_2 = standardize(moment_y_l_2)\n",
        "\n",
        "                moment_z_r_1 = standardize(moment_z_r_1)\n",
        "                moment_z_l_1 = standardize(moment_z_l_1)\n",
        "                moment_z_r_2 = standardize(moment_z_r_2)\n",
        "                moment_z_l_2 = standardize(moment_z_l_2)\n",
        "\n",
        "                # trajectory_x_r_1 = standardize(trajectory_x_r_1)\n",
        "                # trajectory_x_r_2 = standardize(trajectory_x_r_2)\n",
        "                # trajectory_x_l_1 = standardize(trajectory_x_l_1)\n",
        "                # trajectory_x_l_2 = standardize(trajectory_x_l_2)\n",
        "\n",
        "                # trajectory_y_r_1 = standardize(trajectory_y_r_1)\n",
        "                # trajectory_y_r_2 = standardize(trajectory_y_r_2)\n",
        "                # trajectory_y_l_1 = standardize(trajectory_y_l_1)\n",
        "                # trajectory_y_l_2 = standardize(trajectory_y_l_2)\n",
        "\n",
        "                trajectory_z_r_1 = standardize(trajectory_z_r_1)\n",
        "                trajectory_z_r_2 = standardize(trajectory_z_r_2)\n",
        "                trajectory_z_l_1 = standardize(trajectory_z_l_1)\n",
        "                trajectory_z_l_2 = standardize(trajectory_z_l_2)\n",
        "\n",
        "                _features_l_1 = pd.DataFrame(\n",
        "                    np.concatenate(\n",
        "                        # [trajectory_x_l_1, trajectory_y_l_1, trajectory_z_l_1], axis=1\n",
        "                        [trajectory_z_l_1], axis=1\n",
        "                    ),\n",
        "                    columns=[\n",
        "                        # '0_x', '1_x', '2_x', '3_x', '4_x', '5_x', '6_x', '7_x', '8_x', '9_x', '10_x', '11_x',\n",
        "                        # '0_y', '1_y', '2_y', '3_y', '4_y', '5_y', '6_y', '7_y', '8_y', '9_y', '10_y', '11_y',\n",
        "                        # '0_z', '1_z', '2_z', '3_z', '4_z', '5_z', '6_z', '7_z', '8_z', '9_z', '10_z', '11_z'\n",
        "                        # \"fal_x\",\n",
        "                        # \"tam_x\",\n",
        "                        # \"fm5_x\",\n",
        "                        # \"fm1_x\",\n",
        "                        # \"fm2_x\",\n",
        "                        # \"fal_y\",\n",
        "                        # \"tam_y\",\n",
        "                        # \"fm5_y\",\n",
        "                        # \"fm1_y\",\n",
        "                        # \"fm2_y\",\n",
        "                        \"fal_z\",\n",
        "                        \"tam_z\",\n",
        "                        \"fm5_z\",\n",
        "                        \"fm1_z\",\n",
        "                        \"fm2_z\",\n",
        "                    ],\n",
        "                )\n",
        "\n",
        "                _features_l_2 = pd.DataFrame(\n",
        "                    np.concatenate(\n",
        "                        # [trajectory_x_l_2, trajectory_y_l_2, trajectory_z_l_2], axis=1\n",
        "                        [trajectory_z_l_2], axis=1\n",
        "                    ),\n",
        "                    columns=[\n",
        "                        # '0_x', '1_x', '2_x', '3_x', '4_x', '5_x', '6_x', '7_x', '8_x', '9_x', '10_x', '11_x',\n",
        "                        # '0_y', '1_y', '2_y', '3_y', '4_y', '5_y', '6_y', '7_y', '8_y', '9_y', '10_y', '11_y',\n",
        "                        # '0_z', '1_z', '2_z', '3_z', '4_z', '5_z', '6_z', '7_z', '8_z', '9_z', '10_z', '11_z'\n",
        "                        # \"fal_x\",\n",
        "                        # \"tam_x\",\n",
        "                        # \"fm5_x\",\n",
        "                        # \"fm1_x\",\n",
        "                        # \"fm2_x\",\n",
        "                        # \"fal_y\",\n",
        "                        # \"tam_y\",\n",
        "                        # \"fm5_y\",\n",
        "                        # \"fm1_y\",\n",
        "                        # \"fm2_y\",\n",
        "                        \"fal_z\",\n",
        "                        \"tam_z\",\n",
        "                        \"fm5_z\",\n",
        "                        \"fm1_z\",\n",
        "                        \"fm2_z\",\n",
        "                    ],\n",
        "                )\n",
        "\n",
        "                _features_r_1 = pd.DataFrame(\n",
        "                    np.concatenate(\n",
        "                        # [trajectory_x_r_1, trajectory_y_r_1, trajectory_z_r_1], axis=1\n",
        "                        [trajectory_z_r_1], axis=1\n",
        "                    ),\n",
        "                    columns=[\n",
        "                        # '0_x', '1_x', '2_x', '3_x', '4_x', '5_x', '6_x', '7_x', '8_x', '9_x', '10_x', '11_x',\n",
        "                        # '0_y', '1_y', '2_y', '3_y', '4_y', '5_y', '6_y', '7_y', '8_y', '9_y', '10_y', '11_y',\n",
        "                        # '0_z', '1_z', '2_z', '3_z', '4_z', '5_z', '6_z', '7_z', '8_z', '9_z', '10_z', '11_z'\n",
        "                        # \"fal_x\",\n",
        "                        # \"tam_x\",\n",
        "                        # \"fm5_x\",\n",
        "                        # \"fm1_x\",\n",
        "                        # \"fm2_x\",\n",
        "                        # \"fal_y\",\n",
        "                        # \"tam_y\",\n",
        "                        # \"fm5_y\",\n",
        "                        # \"fm1_y\",\n",
        "                        # \"fm2_y\",\n",
        "                        \"fal_z\",\n",
        "                        \"tam_z\",\n",
        "                        \"fm5_z\",\n",
        "                        \"fm1_z\",\n",
        "                        \"fm2_z\",\n",
        "                    ],\n",
        "                )\n",
        "\n",
        "                _features_r_2 = pd.DataFrame(\n",
        "                    np.concatenate(\n",
        "                        # [trajectory_x_r_2, trajectory_y_r_2, trajectory_z_r_2], axis=1\n",
        "                        [trajectory_z_r_2], axis=1\n",
        "                    ),\n",
        "                    columns=[\n",
        "                        # '0_x', '1_x', '2_x', '3_x', '4_x', '5_x', '6_x', '7_x', '8_x', '9_x', '10_x', '11_x',\n",
        "                        # '0_y', '1_y', '2_y', '3_y', '4_y', '5_y', '6_y', '7_y', '8_y', '9_y', '10_y', '11_y',\n",
        "                        # '0_z', '1_z', '2_z', '3_z', '4_z', '5_z', '6_z', '7_z', '8_z', '9_z', '10_z', '11_z'\n",
        "                        # \"fal_x\",\n",
        "                        # \"tam_x\",\n",
        "                        # \"fm5_x\",\n",
        "                        # \"fm1_x\",\n",
        "                        # \"fm2_x\",\n",
        "                        # \"fal_y\",\n",
        "                        # \"tam_y\",\n",
        "                        # \"fm5_y\",\n",
        "                        # \"fm1_y\",\n",
        "                        # \"fm2_y\",\n",
        "                        \"fal_z\",\n",
        "                        \"tam_z\",\n",
        "                        \"fm5_z\",\n",
        "                        \"fm1_z\",\n",
        "                        \"fm2_z\",\n",
        "                    ],\n",
        "                )\n",
        "\n",
        "                _features = pd.concat(\n",
        "                    [_features_l_1, _features_l_2, _features_r_1, _features_r_2], axis=0\n",
        "                )\n",
        "\n",
        "                _features[\"subject\"] = subject\n",
        "                _features[\"velocity\"] = velocity\n",
        "\n",
        "                _target_r_1 = pd.DataFrame(\n",
        "                    np.stack(\n",
        "                        [\n",
        "                            force_x_r_1,\n",
        "                            force_y_r_1,\n",
        "                            force_z_r_1,\n",
        "                            moment_x_r_1,\n",
        "                            moment_y_r_1,\n",
        "                            moment_z_r_1,\n",
        "                        ],\n",
        "                        axis=1,\n",
        "                    ),\n",
        "                    columns=[\"fx\", \"fy\", \"fz\", \"mx\", \"my\", \"mz\"],\n",
        "                )\n",
        "\n",
        "                _target_r_2 = pd.DataFrame(\n",
        "                    np.stack(\n",
        "                        [\n",
        "                            force_x_r_2,\n",
        "                            force_y_r_2,\n",
        "                            force_z_r_2,\n",
        "                            moment_x_r_2,\n",
        "                            moment_y_r_2,\n",
        "                            moment_z_r_2,\n",
        "                        ],\n",
        "                        axis=1,\n",
        "                    ),\n",
        "                    columns=[\"fx\", \"fy\", \"fz\", \"mx\", \"my\", \"mz\"],\n",
        "                )\n",
        "\n",
        "                _target_l_1 = pd.DataFrame(\n",
        "                    np.stack(\n",
        "                        [\n",
        "                            force_x_l_1,\n",
        "                            force_y_l_1,\n",
        "                            force_z_l_1,\n",
        "                            moment_x_l_1,\n",
        "                            moment_y_l_1,\n",
        "                            moment_z_l_1,\n",
        "                        ],\n",
        "                        axis=1,\n",
        "                    ),\n",
        "                    columns=[\"fx\", \"fy\", \"fz\", \"mx\", \"my\", \"mz\"],\n",
        "                )\n",
        "\n",
        "                _target_l_2 = pd.DataFrame(\n",
        "                    np.stack(\n",
        "                        [\n",
        "                            force_x_l_2,\n",
        "                            force_y_l_2,\n",
        "                            force_z_l_2,\n",
        "                            moment_x_l_2,\n",
        "                            moment_y_l_2,\n",
        "                            moment_z_l_2,\n",
        "                        ],\n",
        "                        axis=1,\n",
        "                    ),\n",
        "                    columns=[\"fx\", \"fy\", \"fz\", \"mx\", \"my\", \"mz\"],\n",
        "                )\n",
        "\n",
        "                _target = pd.concat(\n",
        "                    [_target_r_1, _target_r_2, _target_l_1, _target_l_2], axis=0\n",
        "                )\n",
        "\n",
        "                features = pd.concat([features, _features], axis=0, ignore_index=True)\n",
        "                target = pd.concat([target, _target], axis=0, ignore_index=True)\n",
        "\n",
        "                records.append(filename)\n",
        "\n",
        "                n_samples = n_samples + 1\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"ERROR [{subject}/{velocity}/{filename}]: {e}\")\n",
        "                n_bad_samples = n_bad_samples + 1\n",
        "                pass\n",
        "\n",
        "            \n",
        "        \n",
        "    \n",
        "\n",
        "print(\"Number of good samples: \", n_samples)\n",
        "print(\"Number of bad samples: \", n_bad_samples)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = features['fm1_z'].to_numpy().reshape(-1, N_SAMPLES)\n",
        "for i in range(x.shape[0]):\n",
        "    plt.plot(x[i, :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y = target['fz'].to_numpy().reshape(-1, N_SAMPLES)\n",
        "for i in range(y.shape[0]):\n",
        "    plt.plot(y[i, :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "path = '../../Dataset/Processed/data2_f15_t6_n1_all_vel.joblib'\n",
        "data = {\n",
        "    'X': features,\n",
        "    'y': target\n",
        "}\n",
        "dump(data, path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Generating Train Test Sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from joblib import load, dump\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "N_SAMPLES = 1024\n",
        "N_CHANNELS = 15\n",
        "\n",
        "path = '../../Dataset/Processed/data2_f15_t6_n1_high_vel.joblib'\n",
        "data = load(path)\n",
        "features = data['X']\n",
        "target = data['y']\n",
        "\n",
        "# path1 = '../../Dataset/Processed/data2_f72_t3_n1_p1.joblib'\n",
        "# path2 = '../../Dataset/Processed/data2_f72_t3_n1_p2.joblib'\n",
        "\n",
        "# data1 = load(path1)\n",
        "# data2 = load(path2)\n",
        "\n",
        "# features1 = data1['X']\n",
        "# features2 = data2['X']\n",
        "\n",
        "# target1 = data1['y']\n",
        "# target2 = data2['y']\n",
        "\n",
        "# print(features1.shape)\n",
        "# print(features2.shape)\n",
        "\n",
        "# print(target1.shape)\n",
        "# print(target2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# x = features['11_z'].to_numpy().reshape(-1, N_SAMPLES)\n",
        "# for i in range(1120, 1130):\n",
        "#     plt.plot(x[i, :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# features = pd.concat([features1, features2])\n",
        "# target = pd.concat([target1, target2])\n",
        "\n",
        "# print(features.shape)\n",
        "# print(target.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = features.to_numpy().reshape(-1, N_SAMPLES, N_CHANNELS)\n",
        "y = target.to_numpy().reshape(-1, N_SAMPLES, 6)\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(train_X.shape)\n",
        "print(test_X.shape)\n",
        "print(train_y.shape)\n",
        "print(test_y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "path = '../../Dataset/Processed/data2_f15_t6_n1_high_vel_combined.joblib'\n",
        "data = {\n",
        "    'train_X': train_X,\n",
        "    'test_X': test_X,\n",
        "    'train_y': train_y,\n",
        "    'test_y': test_y\n",
        "}\n",
        "dump(data, path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1 align=\"center\">Verification</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# path = '../../Dataset/Processed/data2_f15_t3_n1.joblib'\n",
        "# data = load(path)\n",
        "\n",
        "# features = data['X']\n",
        "# target = data['y']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# x = features['fal_x'].to_numpy().reshape(-1, N_SAMPLES)\n",
        "# for i in range(x.shape[0]):\n",
        "#     plt.plot(x[i, :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# y = target['fz'].to_numpy().reshape(-1, N_SAMPLES)\n",
        "# for i in range(y.shape[0]):\n",
        "#     plt.plot(y[i, :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# y = target['mz'].to_numpy().reshape(-1, N_SAMPLES)\n",
        "# for i in range(y.shape[0]):\n",
        "#     plt.plot(y[i, :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "process_dataset_2.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "b9e8b413bd195f698761fbb7f1cc8940f40efdff75a04973931ad61a6fc56074"
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
