{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LhiDHswgZBby"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import h5py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from ezc3d import c3d\n",
        "from scipy.signal import resample\n",
        "from scipy.io import loadmat, savemat\n",
        "from joblib import load, dump\n",
        "from tqdm import tqdm\n",
        "from scipy.signal import butter, lfilter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlkxCf8PZjwJ",
        "outputId": "af02dbf7-3cdf-481f-baa7-ea5c484f23a4"
      },
      "outputs": [],
      "source": [
        "PATH_DATASETS = '../../Dataset/'\n",
        "PATH_DATASET_2 = 'gait-dbase-2/'\n",
        "\n",
        "N_SAMPLES = 1024\n",
        "FORCE_THRESHOLD = 20\n",
        "TOE_HEIGTH_THRESHOLD = 40"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GrfFilter(object): \n",
        "    @staticmethod\n",
        "    def butter_lowpass(cutoff, fs, order):\n",
        "        nyq = 0.5 * fs\n",
        "        normal_cutoff = cutoff / nyq\n",
        "        b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "        return b, a\n",
        "\n",
        "    def apply(data, cutoff=10, fs=2000, order=2):\n",
        "        b, a = GrfFilter.butter_lowpass(cutoff, fs, order=order)\n",
        "        y = lfilter(b, a, data)\n",
        "        y = y - np.median(y)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def standardize(x):\n",
        "    return (x - np.mean(x, axis=0)) / np.std(x, axis=0)\n",
        "\n",
        "def require_positive(x):\n",
        "    if x < 0:\n",
        "        return 0\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "def clip_overflow(x, max=N_SAMPLES):\n",
        "    if x >= max:\n",
        "        return N_SAMPLES - 1\n",
        "    else:\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJ5MckVigEFX"
      },
      "outputs": [],
      "source": [
        "path = os.path.join(PATH_DATASETS, PATH_DATASET_2)\n",
        "subjects = os.listdir(path)\n",
        "\n",
        "subjects = ['Participant3']\n",
        "\n",
        "features = pd.DataFrame()\n",
        "target = pd.DataFrame()\n",
        "\n",
        "records = []\n",
        "n_samples = 0\n",
        "n_bad_samples = 0\n",
        "\n",
        "for subject in tqdm(subjects):\n",
        "    velocities_path = os.path.join(path, subject, 'Raw_Data')\n",
        "    velocities = os.listdir(velocities_path)\n",
        "\n",
        "    for velocity in velocities:\n",
        "\n",
        "        files_path = os.path.join(velocities_path, velocity)\n",
        "        files = os.listdir(files_path)\n",
        "\n",
        "        for filename in files:\n",
        "            # try:\n",
        "                content = c3d(os.path.join(files_path, filename), extract_forceplat_data=True)\n",
        "            \n",
        "                trajectory_x_r = content['data']['points'][0, 6:11, :]\n",
        "                trajectory_y_r = content['data']['points'][1, 6:11, :]\n",
        "                trajectory_z_r = content['data']['points'][2, 6:11, :]\n",
        "\n",
        "                trajectory_x_l = content['data']['points'][0, 18:23, :]\n",
        "                trajectory_y_l = content['data']['points'][1, 18:23, :]\n",
        "                trajectory_z_l = content['data']['points'][2, 18:23, :]\n",
        "\n",
        "                trajectory_x_r = resample(trajectory_x_r, N_SAMPLES, axis=1).T\n",
        "                trajectory_y_r = resample(trajectory_y_r, N_SAMPLES, axis=1).T\n",
        "                trajectory_z_r = resample(trajectory_z_r, N_SAMPLES, axis=1).T\n",
        "\n",
        "                trajectory_x_l = resample(trajectory_x_l, N_SAMPLES, axis=1).T\n",
        "                trajectory_y_l = resample(trajectory_y_l, N_SAMPLES, axis=1).T\n",
        "                trajectory_z_l = resample(trajectory_z_l, N_SAMPLES, axis=1).T\n",
        "\n",
        "                # ...................... Force X ...........................\n",
        "\n",
        "                # force_x_1 = content['data']['platform'][0]['force'][0, :]\n",
        "                force_x_2 = content['data']['platform'][1]['force'][0, :]\n",
        "                force_x_3 = content['data']['platform'][2]['force'][0, :]\n",
        "                force_x_4 = content['data']['platform'][3]['force'][0, :]\n",
        "                force_x_5 = content['data']['platform'][4]['force'][0, :]\n",
        "                # force_x_6 = content['data']['platform'][5]['force'][0, :]\n",
        "\n",
        "                # force_x_1 = GrfFilter.apply(force_x_1)\n",
        "                force_x_2 = GrfFilter.apply(force_x_2)\n",
        "                force_x_3 = GrfFilter.apply(force_x_3)\n",
        "                force_x_4 = GrfFilter.apply(force_x_4)\n",
        "                force_x_5 = GrfFilter.apply(force_x_5)\n",
        "                # force_x_6 = GrfFilter.apply(force_x_6)\n",
        "\n",
        "                # force_x_1 = resample(force_x_1, N_SAMPLES, axis=0).T\n",
        "                force_x_2 = resample(force_x_2, N_SAMPLES, axis=0).T\n",
        "                force_x_3 = resample(force_x_3, N_SAMPLES, axis=0).T\n",
        "                force_x_4 = resample(force_x_4, N_SAMPLES, axis=0).T\n",
        "                force_x_5 = resample(force_x_5, N_SAMPLES, axis=0).T\n",
        "                # force_x_6 = resample(force_x_6, N_SAMPLES, axis=0).T\n",
        "\n",
        "                # ..................... Force Y ...........................\n",
        "\n",
        "                # force_y_1 = content['data']['platform'][0]['force'][1, :]\n",
        "                force_y_2 = content['data']['platform'][1]['force'][1, :]\n",
        "                force_y_3 = content['data']['platform'][2]['force'][1, :]\n",
        "                force_y_4 = content['data']['platform'][3]['force'][1, :]\n",
        "                force_y_5 = content['data']['platform'][4]['force'][1, :]\n",
        "                # force_y_6 = content['data']['platform'][5]['force'][1, :]\n",
        "\n",
        "                # force_y_1 = GrfFilter.apply(force_y_1)\n",
        "                force_y_2 = GrfFilter.apply(force_y_2)\n",
        "                force_y_3 = GrfFilter.apply(force_y_3)\n",
        "                force_y_4 = GrfFilter.apply(force_y_4)\n",
        "                force_y_5 = GrfFilter.apply(force_y_5)\n",
        "                # force_y_6 = GrfFilter.apply(force_y_6)\n",
        "\n",
        "                # force_y_1 = resample(force_y_1, N_SAMPLES, axis=0).T\n",
        "                force_y_2 = resample(force_y_2, N_SAMPLES, axis=0).T\n",
        "                force_y_3 = resample(force_y_3, N_SAMPLES, axis=0).T\n",
        "                force_y_4 = resample(force_y_4, N_SAMPLES, axis=0).T\n",
        "                force_y_5 = resample(force_y_5, N_SAMPLES, axis=0).T\n",
        "                # force_y_6 = resample(force_y_6, N_SAMPLES, axis=0).T\n",
        "\n",
        "                # ....................... Force Z ............................\n",
        "\n",
        "                # force_z_1 = content['data']['platform'][0]['force'][2, :]\n",
        "                force_z_2 = content['data']['platform'][1]['force'][2, :]\n",
        "                force_z_3 = content['data']['platform'][2]['force'][2, :]\n",
        "                force_z_4 = content['data']['platform'][3]['force'][2, :]\n",
        "                force_z_5 = content['data']['platform'][4]['force'][2, :]\n",
        "                # force_z_6 = content['data']['platform'][5]['force'][2, :]\n",
        "\n",
        "                # force_z_1 = GrfFilter.apply(force_z_1)\n",
        "                force_z_2 = GrfFilter.apply(force_z_2)\n",
        "                force_z_3 = GrfFilter.apply(force_z_3)\n",
        "                force_z_4 = GrfFilter.apply(force_z_4)\n",
        "                force_z_5 = GrfFilter.apply(force_z_5)\n",
        "                # force_z_6 = GrfFilter.apply(force_z_6)\n",
        "\n",
        "                # force_z_1 = resample(force_z_1, N_SAMPLES, axis=0).T\n",
        "                force_z_2 = resample(force_z_2, N_SAMPLES, axis=0).T\n",
        "                force_z_3 = resample(force_z_3, N_SAMPLES, axis=0).T\n",
        "                force_z_4 = resample(force_z_4, N_SAMPLES, axis=0).T\n",
        "                force_z_5 = resample(force_z_5, N_SAMPLES, axis=0).T\n",
        "                # force_z_6 = resample(force_z_6, N_SAMPLES, axis=0).T\n",
        "\n",
        "                # ... Remove all zero GRF samples\n",
        "                if np.mean(force_z_2) <= FORCE_THRESHOLD or np.mean(force_z_3) <= FORCE_THRESHOLD \\\n",
        "                    or np.mean(force_z_4) <= FORCE_THRESHOLD or np.mean(force_z_5) <= FORCE_THRESHOLD:\n",
        "                    n_bad_samples = n_bad_samples + 1\n",
        "                    print('Bad forceplate!')\n",
        "                    continue\n",
        "\n",
        "                grf_combined_x_r = force_x_2 + force_x_4\n",
        "                grf_combined_x_l = force_x_3 + force_x_5\n",
        "                grf_combined_y_r = force_y_2 + force_y_4\n",
        "                grf_combined_y_l = force_y_3 + force_y_5\n",
        "                grf_combined_z_r = force_z_2 + force_z_4\n",
        "                grf_combined_z_l = force_z_3 + force_z_5\n",
        "\n",
        "                grf_mask_r = (grf_combined_z_r >= FORCE_THRESHOLD)\n",
        "                grf_mask_l = (grf_combined_z_l >= FORCE_THRESHOLD)\n",
        "\n",
        "                grf_start_r = np.min(np.argwhere(grf_mask_r == True))\n",
        "                grf_end_r = np.max(np.argwhere(grf_mask_r == True))\n",
        "                grf_start_l = np.min(np.argwhere(grf_mask_l == True))\n",
        "                grf_end_l = np.max(np.argwhere(grf_mask_l == True))\n",
        "\n",
        "                swing_period_r = np.sum(grf_combined_z_r[grf_start_r:grf_end_r] <= FORCE_THRESHOLD)\n",
        "                swing_period_l = np.sum(grf_combined_z_l[grf_start_l:grf_end_l] <= FORCE_THRESHOLD)\n",
        "\n",
        "                roi_start_r = require_positive(grf_start_r - swing_period_r)\n",
        "                roi_end_r = clip_overflow(grf_end_r + swing_period_r)\n",
        "\n",
        "                roi_start_l = require_positive(grf_start_l - swing_period_l)\n",
        "                roi_end_l = clip_overflow(grf_end_l + swing_period_l)\n",
        "\n",
        "                trajectory_x_r = trajectory_x_r[roi_start_l:roi_end_l]\n",
        "                trajectory_x_l = trajectory_x_l[roi_start_r:roi_end_r]\n",
        "                trajectory_y_r = trajectory_y_r[roi_start_l:roi_end_l]\n",
        "                trajectory_y_l = trajectory_y_l[roi_start_r:roi_end_r]\n",
        "                trajectory_z_r = trajectory_z_r[roi_start_l:roi_end_l]\n",
        "                trajectory_z_l = trajectory_z_l[roi_start_r:roi_end_r]\n",
        "\n",
        "                force_x_r = grf_combined_x_r[roi_start_r:roi_end_r]\n",
        "                force_x_l = grf_combined_x_l[roi_start_l:roi_end_l]\n",
        "                force_y_r = grf_combined_y_r[roi_start_r:roi_end_r]\n",
        "                force_y_l = grf_combined_y_l[roi_start_l:roi_end_l]\n",
        "                force_z_r = grf_combined_z_r[roi_start_r:roi_end_r]\n",
        "                force_z_l = grf_combined_z_l[roi_start_l:roi_end_l]\n",
        "\n",
        "                trajectory_x_r = resample(trajectory_x_r, N_SAMPLES, axis=0)\n",
        "                trajectory_x_l = resample(trajectory_x_l, N_SAMPLES, axis=0)\n",
        "                trajectory_y_r = resample(trajectory_y_r, N_SAMPLES, axis=0)\n",
        "                trajectory_y_l = resample(trajectory_y_l, N_SAMPLES, axis=0)\n",
        "                trajectory_z_r = resample(trajectory_z_r, N_SAMPLES, axis=0)\n",
        "                trajectory_z_l = resample(trajectory_z_l, N_SAMPLES, axis=0)\n",
        "\n",
        "                force_x_r = resample(force_x_r, N_SAMPLES, axis=0)\n",
        "                force_x_l = resample(force_x_l, N_SAMPLES, axis=0)\n",
        "                force_y_r = resample(force_y_r, N_SAMPLES, axis=0)\n",
        "                force_y_l = resample(force_y_l, N_SAMPLES, axis=0)\n",
        "                force_z_r = resample(force_z_r, N_SAMPLES, axis=0)\n",
        "                force_z_l = resample(force_z_l, N_SAMPLES, axis=0)\n",
        "\n",
        "                # ... Standardize\n",
        "                trajectory_x_r = standardize(trajectory_x_r)\n",
        "                trajectory_x_l = standardize(trajectory_x_l)\n",
        "                trajectory_y_r = standardize(trajectory_y_r)\n",
        "                trajectory_y_l = standardize(trajectory_y_l)\n",
        "                trajectory_z_r = standardize(trajectory_z_r)\n",
        "                trajectory_z_l = standardize(trajectory_z_l)\n",
        "\n",
        "                force_x_r = standardize(force_x_r)\n",
        "                force_x_l = standardize(force_x_l)\n",
        "                force_y_r = standardize(force_y_r)\n",
        "                force_y_l = standardize(force_y_l)\n",
        "                force_z_r = standardize(force_z_r)\n",
        "                force_z_l = standardize(force_z_l)\n",
        "\n",
        "\n",
        "                _features_l = pd.DataFrame(\n",
        "                    np.concatenate([trajectory_x_l, trajectory_y_l, trajectory_z_l], axis=1),\n",
        "                    columns=[\n",
        "                        '7_x', '8_x', '9_x', '10_x', '11_x',\n",
        "                        '7_y', '8_y', '9_y', '10_y', '11_y',\n",
        "                        '7_z', '8_z', '9_z', '10_z', '11_z'\n",
        "                    ]\n",
        "                )\n",
        "\n",
        "                _features_r = pd.DataFrame(\n",
        "                    np.concatenate([trajectory_x_r, trajectory_y_r, trajectory_z_r], axis=1),\n",
        "                    columns=[\n",
        "                        '7_x', '8_x', '9_x', '10_x', '11_x',\n",
        "                        '7_y', '8_y', '9_y', '10_y', '11_y',\n",
        "                        '7_z', '8_z', '9_z', '10_z', '11_z'\n",
        "                    ]\n",
        "                )\n",
        "\n",
        "                _features = pd.concat([_features_l, _features_r], axis=0)\n",
        "\n",
        "                _target_r = pd.DataFrame(\n",
        "                    np.stack([force_x_r, force_y_r, force_z_r], axis=1),\n",
        "                    columns=['fx', 'fy', 'fz']\n",
        "                )\n",
        "\n",
        "                _target_l = pd.DataFrame(\n",
        "                    np.stack([force_x_l, force_y_l, force_z_l], axis=1),\n",
        "                    columns=['fx', 'fy', 'fz']\n",
        "                )\n",
        "\n",
        "                _target = pd.concat([_target_r, _target_l], axis=0)\n",
        "\n",
        "                features = pd.concat([features, _features], axis=0, ignore_index=True)\n",
        "                target = pd.concat([target, _target], axis=0, ignore_index=True)\n",
        "\n",
        "                records.append(filename)\n",
        "\n",
        "                n_samples = n_samples + 1\n",
        "\n",
        "            # except Exception as e:\n",
        "            #     print(f'ERROR [{subject}/{velocity}/{filename}]: {e}')\n",
        "            #     n_bad_samples = n_bad_samples + 1\n",
        "            #     pass\n",
        "\n",
        "print('Number of good samples: ', n_samples)\n",
        "print('Number of bad samples: ', n_bad_samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "path = '../../Dataset/Processed/data2.joblib'\n",
        "data = {\n",
        "    'X': features,\n",
        "    'y': target\n",
        "}\n",
        "# dump(data, path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1 align=\"center\">Verification</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = features['11_z'].to_numpy().reshape(-1, N_SAMPLES)\n",
        "for i in range(100, 200):\n",
        "    plt.plot(x[i, :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y = target['fz'].to_numpy().reshape(-1, N_SAMPLES)\n",
        "for i in range(196, 200):\n",
        "    plt.plot(y[i, :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "process_dataset_2.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "b9e8b413bd195f698761fbb7f1cc8940f40efdff75a04973931ad61a6fc56074"
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
